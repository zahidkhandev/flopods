# Pod Execution System - Complete Architecture Documentation

## ğŸ“š Table of Contents

1. [System Overview](#system-overview)
2. [Why We Need These Components](#why-we-need-these-components)
3. [Component Deep Dive](#component-deep-dive)
4. [Execution Flow](#execution-flow)
5. [Context Resolution](#context-resolution)
6. [Queue System (BullMQ â†” SQS)](#queue-system)
7. [One-Click Queue Migration](#one-click-queue-migration)
8. [Example Usage](#example-usage)

---

## System Overview

The Pod Execution System is the **heart of Flopods's AI workflow engine**. It orchestrates the execution of LLM (Large Language Model) pods in a flow, managing:

- **Context Resolution** - Building context from upstream pod outputs
- **Variable Interpolation** - Replacing `{{pod_id}}` references with actual outputs
- **Queue Management** - Async execution with BullMQ (dev) or SQS (prod)
- **Real-time Updates** - WebSocket notifications for execution status
- **Cost Tracking** - Token usage and cost calculation per execution

---

## Why We Need These Components

### 1. **Context Resolution Service** (`context-resolution.service.ts`)

**Problem:** Pods in a flow are connected (Pod A â†’ Pod B â†’ Pod C). When executing Pod B, it needs Pod A's output as context.

**Solution:** The context resolution service:

- Finds all upstream connected pods (those that feed into current pod)
- Retrieves their latest execution outputs
- Builds a variable map (`pod_a_id` â†’ `"Pod A's actual output"`)
- Enables variable interpolation in prompts

**Example:**

```
Pod A: "What is quantum computing?"
Output: "Quantum computing uses qubits to process information..."

Pod B System Prompt: "Summarize this: {{pod_a_id}}"
After interpolation: "Summarize this: Quantum computing uses qubits to process information..."
```

**Why Critical:**

- Without it, pods can't reference each other's outputs
- No way to build complex multi-step AI workflows
- Users would have to manually copy-paste outputs between pods

---

### 2. **Execution Queue Service** (`execution-queue.service.ts`)

**Problem:** LLM API calls can take 5-30 seconds. Blocking the HTTP request thread causes:

- Timeout errors for long-running executions
- Poor user experience (stuck waiting)
- Server resource exhaustion under load

**Solution:** Queue-based async execution:

- User clicks "Execute" â†’ Returns immediately with `executionId`
- Execution job queued in background (BullMQ/SQS)
- Worker processes job asynchronously
- Real-time status updates via WebSocket

**Why Critical:**

- **Scalability** - Handle 1000s of concurrent executions
- **Reliability** - Retry failed executions automatically
- **User Experience** - Non-blocking, responsive UI
- **Resource Efficiency** - Controlled concurrency (max 10 workers)

---

### 3. **Execution Service** (`execution.service.ts`)

**Problem:** Need a central orchestrator that:

- Validates pod access (workspace permissions)
- Fetches pod configuration from DynamoDB
- Resolves context from upstream pods
- Calls the correct LLM provider (OpenAI/Claude/Gemini)
- Tracks costs and usage
- Updates pod status in real-time

**Solution:** The execution service is the **main coordinator** that:

1. Validates the request
2. Resolves context using `ContextResolutionService`
3. Interpolates variables in prompts
4. Calls LLM provider
5. Calculates costs
6. Saves execution results
7. Updates pod status

**Why Critical:**

- Single source of truth for execution logic
- Ensures consistent behavior across sync/async modes
- Handles all error cases gracefully
- Tracks every execution for audit and billing

---

## Component Deep Dive

### Context Resolution Service

**File:** `context-resolution.service.ts`

**Key Methods:**

```typescript
// 1. Resolve all upstream pod outputs
async resolveContext(podId: string, flowId: string): Promise<ContextChain>

// 2. Interpolate variables in text
interpolateVariables(text: string, variables: Record<string, string>): string

// 3. Get topological execution order
async getExecutionOrder(flowId: string): Promise<string[]>
```

**Data Structures:**

```typescript
interface ContextChain {
  pod: { id: string; type: PodType };
  context: ResolvedContext[]; // Upstream pod outputs
  variables: Record<string, string>; // pod_id â†’ output mapping
}

interface ResolvedContext {
  podId: string;
  output: string; // Actual LLM response
  executionId?: string;
  timestamp: Date;
}
```

**Algorithm:**

1. **Find Upstream Pods:**

   ```sql
   SELECT sourcePodId FROM edges
   WHERE flowId = ? AND targetPodId = ?
   ```

2. **Get Latest Execution for Each:**

   ```sql
   SELECT responseMetadata FROM podExecution
   WHERE podId = ? AND status = 'COMPLETED'
   ORDER BY finishedAt DESC LIMIT 1
   ```

3. **Extract Output:**
   - OpenAI: `response.choices[0].message.content`
   - Anthropic: `response.content[0].text`
   - Gemini: `response.candidates[0].content.parts[0].text`

4. **Build Variable Map:**

   ```typescript
   variables['pod_abc123'] = 'Quantum computing uses qubits...';
   ```

5. **Interpolate in Prompts:**
   ```typescript
   text.replace(/\{\{([a-zA-Z0-9_-]+)(?:\.output)?\}\}/g, (match, podId) => {
     return variables[podId] || match;
   });
   ```

---

### Execution Queue Service

**File:** `execution-queue.service.ts`

**Key Features:**

1. **Queue Creation:**

   ```typescript
   this.executionQueue = this.queueFactory.createQueue('pod-executions', 10);
   // 10 = max concurrent workers
   ```

2. **Job Enqueueing:**

   ```typescript
   async queueExecution(data: ExecutionJobData): Promise<string> {
     const jobId = await this.executionQueue.add('execute-pod', data, {
       jobId: data.executionId, // Use execution ID as job ID for idempotency
     });

     // Emit WebSocket event
     this.flowGateway.broadcastToFlow(data.flowId, 'execution:queued', {...});

     return jobId;
   }
   ```

3. **Job Processing:**

   ```typescript
   private async processExecution(job: any) {
     const { executionId, podId, workspaceId, userId, flowId, ...params } = job.data;

     // Update status to RUNNING
     await this.updateExecutionStatus(executionId, PodExecutionStatus.RUNNING);
     this.flowGateway.broadcastToFlow(flowId, 'execution:running', {...});

     try {
       // Execute the pod
       const result = await this.executionService.executePodInternal({
         executionId, podId, workspaceId, userId, ...params
       });

       // Emit success
       this.flowGateway.broadcastToFlow(flowId, 'execution:completed', {result});

       return result;
     } catch (error) {
       // Emit error
       this.flowGateway.broadcastToFlow(flowId, 'execution:error', {error});
       throw error;
     }
   }
   ```

4. **Real-time Status Updates:**
   - `execution:queued` - Job added to queue
   - `execution:running` - Worker started processing
   - `execution:completed` - Success
   - `execution:error` - Failure

---

### Execution Service

**File:** `execution.service.ts`

**Execution Pipeline:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. VALIDATE POD                                             â”‚
â”‚    - Check workspace access                                 â”‚
â”‚    - Verify pod type (must be LLM_PROMPT)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FETCH POD CONFIG FROM DYNAMODB                           â”‚
â”‚    - Provider (OpenAI/Claude/Gemini)                        â”‚
â”‚    - Model (gpt-4o, claude-3-5-sonnet, etc.)                â”‚
â”‚    - System prompt, temperature, maxTokens                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. RESOLVE CONTEXT                                          â”‚
â”‚    - Find upstream pods (edges pointing TO this pod)        â”‚
â”‚    - Get their latest outputs                               â”‚
â”‚    - Build variable map: {pod_id: "output"}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. INTERPOLATE VARIABLES                                    â”‚
â”‚    - Replace {{pod_a_id}} in system prompt                  â”‚
â”‚    - Replace {{pod_b_id}} in user messages                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. GET WORKSPACE API KEY                                    â”‚
â”‚    - Fetch encrypted key from database                      â”‚
â”‚    - Decrypt using AES-256-GCM                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. EXECUTE LLM REQUEST                                      â”‚
â”‚    - Call provider (OpenAI/Claude/Gemini)                   â”‚
â”‚    - Stream or wait for response                            â”‚
â”‚    - Extract response content                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. CALCULATE COSTS                                          â”‚
â”‚    - Fetch model pricing from database                      â”‚
â”‚    - inputCost = (promptTokens / 1M) * pricing.inputCost    â”‚
â”‚    - outputCost = (completionTokens / 1M) * pricing.output  â”‚
â”‚    - reasoningCost = (reasoningTokens / 1M) * pricing.reas  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. SAVE RESULTS                                             â”‚
â”‚    - Update podExecution (status, tokens, cost, response)   â”‚
â”‚    - Track API key usage                                    â”‚
â”‚    - Update pod status (lastExecutionId)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. RETURN RESULT                                            â”‚
â”‚    - executionId, content, usage, cost                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Execution Flow

### Synchronous Execution (Immediate Response)

```
USER REQUEST
    â†“
POST /api/workspaces/:id/executions
{
  "podId": "pod_abc123",
  "messages": [{"role": "user", "content": "Explain {{pod_previous}}"}],
  "async": false
}
    â†“
ExecutionService.executePod()
    â†“
[Pipeline executes - see diagram above]
    â†“
RESPONSE (5-30 seconds later)
{
  "executionId": "exec_xyz789",
  "content": "Quantum computing is...",
  "usage": {...},
  "cost": {...}
}
```

### Asynchronous Execution (Queue-Based)

```
USER REQUEST
    â†“
POST /api/workspaces/:id/executions
{
  "podId": "pod_abc123",
  "messages": [...],
  "async": true  â† KEY DIFFERENCE
}
    â†“
ExecutionController.executePod()
    â†“
ExecutionQueueService.queueExecution()
    â†“
Job added to queue (BullMQ/SQS)
    â†“
IMMEDIATE RESPONSE (< 100ms)
{
  "executionId": "exec_xyz789",
  "status": "queued"
}
    â†“
WebSocket Event â†’ Frontend
{
  "type": "execution:queued",
  "executionId": "exec_xyz789",
  "podId": "pod_abc123",
  "status": "QUEUED"
}

    â±ï¸ MEANWHILE (background worker)

Queue Worker picks up job
    â†“
ExecutionQueueService.processExecution()
    â†“
WebSocket Event â†’ "execution:running"
    â†“
ExecutionService.executePodInternal()
    â†“
[Pipeline executes]
    â†“
WebSocket Event â†’ "execution:completed"
{
  "type": "execution:completed",
  "executionId": "exec_xyz789",
  "result": {...}
}
```

**Frontend receives 3 WebSocket events:**

1. `execution:queued` - Job added to queue
2. `execution:running` - Worker started
3. `execution:completed` - Result ready

---

## Context Resolution

### Example Flow with 3 Connected Pods

**Setup:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pod A      â”‚  Research Pod
â”‚  (RESEARCH)  â”‚  Prompt: "What is quantum computing?"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ (edge)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pod B      â”‚  Summary Pod
â”‚  (SUMMARY)   â”‚  System: "Summarize this: {{pod_a}}"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  User: "Make it 3 sentences"
       â”‚
       â†“ (edge)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pod C      â”‚  Action Pod
â”‚  (ACTIONS)   â”‚  System: "Extract action items from: {{pod_b}}"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Execution Sequence:**

**1. Execute Pod A:**

```typescript
// No upstream pods â†’ No context
contextChain = {
  pod: { id: 'pod_a', type: 'LLM_PROMPT' },
  context: [],
  variables: {},
};

// Final prompt to LLM
messages = [
  { role: 'system', content: 'You are a helpful AI assistant' },
  { role: 'user', content: 'What is quantum computing?' },
];

// Response saved
response = 'Quantum computing uses qubits to process information. Unlike classical bits...';
```

**2. Execute Pod B:**

```typescript
// Find upstream pods
upstreamEdges = [{ sourcePodId: 'pod_a', targetPodId: 'pod_b' }]

// Get Pod A's latest execution
podA_output = "Quantum computing uses qubits to process information. Unlike classical bits..."

// Build context
contextChain = {
  pod: { id: 'pod_b', type: 'LLM_PROMPT' },
  context: [
    {
      podId: 'pod_a',
      output: "Quantum computing uses qubits...",
      executionId: 'exec_123',
      timestamp: Date()
    }
  ],
  variables: {
    'pod_a': "Quantum computing uses qubits..."
  }
}

// Interpolate system prompt
systemPrompt = "Summarize this: {{pod_a}}"
â†“
systemPrompt = "Summarize this: Quantum computing uses qubits to process information..."

// Final prompt to LLM
messages = [
  { role: 'system', content: 'Summarize this: Quantum computing uses qubits...' },
  { role: 'user', content: 'Make it 3 sentences' }
]

// Response saved
response = "Quantum computing leverages qubits. It processes information differently. This enables exponential speedup."
```

**3. Execute Pod C:**

```typescript
// Find upstream pods
upstreamEdges = [{ sourcePodId: 'pod_b', targetPodId: 'pod_c' }]

// Get Pod B's latest execution
podB_output = "Quantum computing leverages qubits. It processes information differently. This enables exponential speedup."

// Build context
contextChain = {
  pod: { id: 'pod_c', type: 'LLM_PROMPT' },
  context: [
    {
      podId: 'pod_b',
      output: "Quantum computing leverages qubits...",
      executionId: 'exec_456',
      timestamp: Date()
    }
  ],
  variables: {
    'pod_b': "Quantum computing leverages qubits..."
  }
}

// Interpolate system prompt
systemPrompt = "Extract action items from: {{pod_b}}"
â†“
systemPrompt = "Extract action items from: Quantum computing leverages qubits. It processes information differently..."

// Final prompt to LLM
messages = [
  { role: 'system', content: 'Extract action items from: Quantum computing leverages qubits...' },
  { role: 'user', content: '' }  // No additional user message
]

// Response saved
response = "1. Research qubits\n2. Study quantum information processing\n3. Learn about quantum speedup"
```

---

## Queue System

### Why We Need a Queue

**Without Queue (Synchronous Only):**

```
User clicks Execute
  â†“
HTTP Request starts
  â†“
Wait 5-30 seconds (LLM API call)
  â†“
Response returns
```

**Problems:**

- âŒ Browser timeout after 30s
- âŒ Server thread blocked (can't handle other requests)
- âŒ No retry on failure
- âŒ No concurrency control (can overwhelm LLM API)
- âŒ Poor UX (user stuck waiting)

**With Queue (Asynchronous):**

```
User clicks Execute
  â†“
HTTP Request returns immediately (< 100ms)
  â†“
Job queued for background processing
  â†“
Worker picks up job when available
  â†“
WebSocket updates frontend in real-time
```

**Benefits:**

- âœ… Instant response (< 100ms)
- âœ… Automatic retries (3 attempts with exponential backoff)
- âœ… Concurrency control (max 10 workers)
- âœ… Graceful degradation (queue persists across restarts)
- âœ… Better UX (real-time progress updates)

---

### Queue Architecture

**Development (BullMQ + Redis):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Controller    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ queueExecution()
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QueueFactory   â”‚ â† creates adapter
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RedisQueueAdapterâ”‚ â† BullMQ wrapper
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis (local) â”‚ â† Job storage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker Pool   â”‚ â† 10 concurrent workers
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ processExecution()
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ExecutionServiceâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Production (AWS SQS):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Controller    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ queueExecution()
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QueueFactory   â”‚ â† creates adapter
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SqsQueueAdapter â”‚ â† SQS wrapper
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS SQS       â”‚ â† Job storage (managed)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker Pool   â”‚ â† Auto-scaled workers (Fargate/Lambda)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ processExecution()
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ExecutionServiceâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## One-Click Queue Migration

### Current Setup (Already Done!)

**File:** `apps/backend/src/common/queue/queue.factory.ts`

```typescript
@Injectable()
export class QueueFactory {
  constructor(private readonly config: ConfigService) {}

  createQueue(queueName: string, maxConcurrency: number): QueueAdapter {
    const backend = this.config.get<string>('QUEUE_BACKEND') || 'redis';

    if (backend === 'sqs') {
      return new SqsQueueAdapter(queueName, maxConcurrency, this.config);
    } else {
      return new RedisQueueAdapter(queueName, maxConcurrency, this.config);
    }
  }
}
```

### Migration Steps (Literally 1 Change)

**From BullMQ to SQS:**

**Step 1:** Update `.env` file

```bash
# Change this ONE line:
QUEUE_BACKEND=redis  # â† From this
QUEUE_BACKEND=sqs    # â† To this

# Add SQS config (if not already present):
AWS_SQS_QUEUE_URL=https://sqs.ap-south-1.amazonaws.com/715841334028/flopods-executions
AWS_SQS_REGION=ap-south-1
```

**Step 2:** Restart backend

```bash
yarn dev:backend
```

**That's it!** The system now uses SQS instead of Redis.

---

### How It Works

**Queue Adapter Interface:**

```typescript
export interface QueueAdapter {
  add(jobName: string, data: any, options?: any): Promise<string>;
  process(handler: (job: any) => Promise<any>): void;
  close(): Promise<void>;
  cancel(jobId: string): Promise<boolean>;
  getMetrics(): Promise<any>;
  getJobStatus(jobId: string): Promise<any>;
}
```

**Both adapters implement the same interface:**

**RedisQueueAdapter (BullMQ):**

```typescript
class RedisQueueAdapter implements QueueAdapter {
  private queue: Queue;

  async add(jobName: string, data: any, options?: any): Promise<string> {
    const job = await this.queue.add(jobName, data, options);
    return job.id;
  }

  process(handler: (job: any) => Promise<any>): void {
    new Worker(this.queueName, handler, {...});
  }

  // ... other methods
}
```

**SqsQueueAdapter (AWS SQS):**

```typescript
class SqsQueueAdapter implements QueueAdapter {
  private sqsClient: SQSClient;

  async add(jobName: string, data: any, options?: any): Promise<string> {
    const response = await this.sqsClient.send(
      new SendMessageCommand({
        QueueUrl: this.queueUrl,
        MessageBody: JSON.stringify({ jobName, data }),
      }),
    );
    return response.MessageId;
  }

  process(handler: (job: any) => Promise<any>): void {
    this.pollMessages(handler); // Long polling SQS
  }

  // ... other methods
}
```

**ExecutionQueueService doesn't care which implementation:**

```typescript
// This code works with BOTH BullMQ and SQS:
this.executionQueue = this.queueFactory.createQueue('pod-executions', 10);

await this.executionQueue.add('execute-pod', data, { jobId });
```

---

### Environment Variables

**`.env` file:**

```bash
# ==========================================
# QUEUE CONFIGURATION
# ==========================================

# Queue Backend: 'redis' (dev) or 'sqs' (prod)
QUEUE_BACKEND=redis

# Redis (Development - BullMQ)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_TLS_ENABLED=false

# AWS SQS (Production)
AWS_SQS_ACCESS_KEY_ID=AKIA...
AWS_SQS_SECRET_ACCESS_KEY=...
AWS_SQS_QUEUE_URL=https://sqs.ap-south-1.amazonaws.com/715841334028/flopods-executions
AWS_SQS_REGION=ap-south-1
```

**To switch:** Just change `QUEUE_BACKEND=redis` to `QUEUE_BACKEND=sqs`

---

## Example Usage

### Execute Pod Synchronously

**Request:**

```http
POST /api/v1/workspaces/cm2abc123/executions
Authorization: Bearer <token>
Content-Type: application/json

{
  "podId": "pod_xyz789",
  "messages": [
    {
      "role": "user",
      "content": "Explain quantum computing"
    }
  ],
  "provider": "OPENAI",
  "model": "gpt-4o",
  "temperature": 0.7,
  "maxTokens": 2000,
  "async": false
}
```

**Response (after 5-10 seconds):**

```json
{
  "executionId": "exec_cm2def456",
  "content": "Quantum computing is a revolutionary approach to computation...",
  "usage": {
    "promptTokens": 42,
    "completionTokens": 357,
    "totalTokens": 399,
    "reasoningTokens": 0,
    "cachedTokens": 0
  },
  "cost": {
    "inputCost": 0.000105,
    "outputCost": 0.001785,
    "reasoningCost": 0,
    "totalCost": 0.00189
  }
}
```

---

### Execute Pod Asynchronously (Queue)

**Request:**

```http
POST /api/v1/workspaces/cm2abc123/executions
Authorization: Bearer <token>
Content-Type: application/json

{
  "podId": "pod_xyz789",
  "messages": [
    {
      "role": "user",
      "content": "Explain quantum computing in detail with {{pod_previous}} context"
    }
  ],
  "async": true  â† KEY DIFFERENCE
}
```

**Immediate Response (< 100ms):**

```json
{
  "executionId": "exec_cm2def456",
  "status": "queued"
}
```

**WebSocket Events (received over time):**

**Event 1 (immediately):**

```json
{
  "type": "execution:queued",
  "executionId": "exec_cm2def456",
  "podId": "pod_xyz789",
  "status": "QUEUED"
}
```

**Event 2 (when worker picks up job):**

```json
{
  "type": "execution:running",
  "executionId": "exec_cm2def456",
  "podId": "pod_xyz789",
  "status": "RUNNING"
}
```

**Event 3 (when completed):**

```json
{
  "type": "execution:completed",
  "executionId": "exec_cm2def456",
  "podId": "pod_xyz789",
  "status": "COMPLETED",
  "result": {
    "executionId": "exec_cm2def456",
    "content": "Quantum computing is a revolutionary approach...",
    "usage": {...},
    "cost": {...}
  }
}
```

---

### Get Execution History

**Request:**

```http
GET /api/v1/workspaces/cm2abc123/executions/pod/pod_xyz789?limit=10
Authorization: Bearer <token>
```

**Response:**

```json
[
  {
    "id": "exec_cm2def456",
    "podId": "pod_xyz789",
    "status": "COMPLETED",
    "provider": "OPENAI",
    "modelId": "gpt-4o",
    "modelName": "gpt-4o-2024-05-13",
    "inputTokens": 42,
    "outputTokens": 357,
    "reasoningTokens": 0,
    "costInUsd": "0.001890",
    "startedAt": "2025-10-24T18:00:00.000Z",
    "finishedAt": "2025-10-24T18:00:05.432Z",
    "runtimeInMs": 5432,
    "errorMessage": null,
    "errorCode": null
  },
  ...
]
```

---

### Cancel Queued Execution

**Request:**

```http
DELETE /api/v1/workspaces/cm2abc123/executions/exec_cm2def456
Authorization: Bearer <token>
```

**Response:**

```http
HTTP/1.1 204 No Content
```

---

## Summary

### What We Built

1. **Context Resolution Service** - Enables pods to reference each other's outputs
2. **Execution Queue Service** - Async execution with BullMQ/SQS
3. **Execution Service** - Main orchestrator for pod execution
4. **Queue Factory** - Abstraction for easy BullMQ â†” SQS migration

### Why It Matters

- **Scalability** - Queue handles 1000s of concurrent executions
- **Reliability** - Automatic retries, graceful degradation
- **User Experience** - Real-time updates, instant responses
- **Flexibility** - One-line change to switch queue backends
- **Context-Aware** - Pods can build on each other's outputs

### Migration Path

**Development:** BullMQ + Redis (local, fast, easy to debug)
**Production:** AWS SQS (managed, scalable, no infrastructure)

**To switch:** Change ONE environment variable (`QUEUE_BACKEND=sqs`)

---

**ğŸ‰ That's the complete Pod Execution System!**
